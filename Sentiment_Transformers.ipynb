{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment - Transformers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOPvXZb9ke3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a942cf-3fb2-467e-a08f-15352c97f754"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount = True)\n",
        "dataset_path = 'gdrive/My Drive/Deep Learning/sentiment analysis/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnC-9IsUmO38"
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from transformers import BertConfig\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFuTJMVUmXpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46af8798-6e96-4a4c-b97f-c788f2d85851"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVL0BlKXwJMq"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbiFCek_xGw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb270fc0-d2a4-4e0c-cc3c-f076ea423af8"
      },
      "source": [
        "len(tokenizer.vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTNoWz2Y8NKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e314c00e-38e2-4529-ae8e-7bb46eff28cf"
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
        "\n",
        "print(max_input_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTznVjvhyFAo"
      },
      "source": [
        "def tokenize_and_cut(sentence):\n",
        "    tokens = tokenizer.tokenize(sentence) \n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKMaa9NEyNxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d7f9dec-d17e-4b6b-8487-f5a9c1b2cf6e"
      },
      "source": [
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101 102 0 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufKFV9CpyTUQ"
      },
      "source": [
        "from torchtext import data\n",
        "\n",
        "TEXT = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = tokenize_and_cut,\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Owx8gK4yjDb"
      },
      "source": [
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path=dataset_path, train=\"sst_train.csv\", \n",
        "    validation=\"sst_dev.csv\", test=\"sst_test.csv\",format=\"csv\", skip_header=True, \n",
        "    fields=[('text', TEXT), ('truth', LABEL)]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hP9lEyBzJqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dc02124-4f24-4932-b205-46ce63ddadcd"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of valid examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 8544\n",
            "Number of valid examples: 1101\n",
            "Number of testing examples: 2210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx00BYaaq5Do"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiSFCtjCrIjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675edcbe-aaf9-4cd0-bf11-aefcbf4e18bd"
      },
      "source": [
        "print(vars(train_data.examples[6]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': [2074, 1996, 4428, 2920, 1999, 4526, 1996, 21323, 4138, 2791, 1997, 1996, 13425, 1999, 2023, 9610, 10464, 28817, 3217, 1997, 12013, 1998, 2422, 2003, 26137, 1012], 'truth': '5'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60KlEhi-rMdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b0db98-30a5-4813-d8f4-a4fcbcd5253d"
      },
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[6])['text'])\n",
        "\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['just', 'the', 'labour', 'involved', 'in', 'creating', 'the', 'layered', 'rich', '##ness', 'of', 'the', 'imagery', 'in', 'this', 'chi', '##aro', '##scu', '##ro', 'of', 'madness', 'and', 'light', 'is', 'astonishing', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTVhELcKzOMJ"
      },
      "source": [
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY5H0UCxsJOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0828a790-a71d-4c6a-b33f-3bb9b35e1abb"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f42487f4d08>, {'4': 0, '2': 1, '3': 2, '5': 3, '1': 4})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqSEVglx9Xpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eabd2ca-81cc-425f-d73f-9a60a3dadc4a"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# keep in mind the sort_key option \n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), sort_key=lambda x: len(x.text),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sort_within_batch=True,\n",
        "    device=device)\n",
        "LABEL.vocab.freqs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'1': 1092, '2': 2218, '3': 1624, '4': 2322, '5': 1288})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT68SzzDVBEN"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cksRo5qXBsrb"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BERTGRUSentiment(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        #self.config = config\n",
        "        self.bert = bert\n",
        "        \n",
        "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "        #print(embedding_dim)\n",
        "        bert.config.output_hidden_states = True\n",
        "        #print(bert.config)\n",
        "        self.rnn = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [batch size, sent len]\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            out_bert = self.bert(text) #, config = self.config)\n",
        "            #embedded = out_bert[0]\n",
        "            #print(embedded.shape)\n",
        "        #print(len(out_bert[2]))\n",
        "        last = out_bert[2]\n",
        "        l_1, l_2, l_3, l_4 = last[-1], last[-2], last[-3], last[-4]\n",
        "        #print(l_1.shape)\n",
        "        embedded = torch.cat((l_1,l_2,l_3,l_4), dim = 1)\n",
        "        #print(embedded.shape)       \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        _, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #hidden = [n layers * n directions, batch size, emb dim]\n",
        "        \n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "                \n",
        "        #hidden = [batch size, hid dim]\n",
        "        #print(hidden.shape)\n",
        "        output = self.out(hidden)\n",
        "        #print(output.shape)\n",
        "        #output = [batch size, out dim]\n",
        "        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrSBnD-uLeC3"
      },
      "source": [
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 5\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model = BERTGRUSentiment(bert,\n",
        "                         HIDDEN_DIM,\n",
        "                         OUTPUT_DIM,\n",
        "                         N_LAYERS,\n",
        "                         BIDIRECTIONAL,\n",
        "                         DROPOUT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lthLuDFpCGIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "681717ff-727a-4b8c-f1f6-7b2fe2e87adc"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,761,221 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFbraQ4nzk8m"
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy4K7ZwSCNYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38518b0f-bbc1-4714-e661-060c0fcbed3e"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,761,221 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puOZniDaSlzn"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRFkkTxyCTrc"
      },
      "source": [
        "model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)#,weight_decay=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8qgiZP0wLTq"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "def binary_accuracy(preds1, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    #print(\"Here\")\n",
        "    preds, ind= torch.max(F.softmax(preds1),1)\n",
        "    correct = (ind == y).float()\n",
        "    acc = correct.sum()/float(len(correct))\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djr3YbaHC6Eg"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        #print(predictions.shape, batch.truth)\n",
        "        loss = criterion(predictions, batch.truth)\n",
        "        #print(loss)\n",
        "        acc = binary_accuracy(predictions, batch.truth)\n",
        "        #print(acc)\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fESTz3KxDGmh"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.truth)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.truth)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfB6_4l4DVgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7385ceaf-142d-4762-bd8a-f0e4b3c67356"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "        \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'bert-model.pt')\n",
        "    \n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.347 | Train Acc: 40.05%\n",
            "\t Val. Loss: 1.219 |  Val. Acc: 46.01%\n",
            "\tTrain Loss: 1.189 | Train Acc: 47.76%\n",
            "\t Val. Loss: 1.188 |  Val. Acc: 46.64%\n",
            "\tTrain Loss: 1.141 | Train Acc: 50.05%\n",
            "\t Val. Loss: 1.193 |  Val. Acc: 47.46%\n",
            "\tTrain Loss: 1.102 | Train Acc: 52.28%\n",
            "\t Val. Loss: 1.173 |  Val. Acc: 48.45%\n",
            "\tTrain Loss: 1.057 | Train Acc: 53.52%\n",
            "\t Val. Loss: 1.186 |  Val. Acc: 48.86%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER9FN6pJEYA3"
      },
      "source": [
        "test_add_notan = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db59ayP8DeKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df3bfc81-ed61-4475-f447-363cf079940e"
      },
      "source": [
        "model.load_state_dict(torch.load('bert-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.128 | Test Acc: 50.90%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Q_9_E22E8A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c5bbcc89-228b-4e71-faa4-ad7adaae355a"
      },
      "source": [
        "test_add_notan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[46.919642857142854, 48.16964285714286, 46.517857142857146, 47.58928571428571]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 514
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3p756ziEhsj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92a52e09-c9c0-4d8b-eab0-ad0376e78ad8"
      },
      "source": [
        "sum(test_norm_tanh)/len(test_norm_tanh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47.27678571428571"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X0L8wOFGOcO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3189be9e-1dc2-4e41-fe5f-0d4109b96321"
      },
      "source": [
        "sum(test_1)/len(test_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47.69642857142857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjC5kpfsNHkj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c4a1c809-6859-4034-8088-870c26a31ac3"
      },
      "source": [
        "sum(test)/len(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47.84821428571429"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgPCCa5JX3PG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "a19b6e99-26d9-48d4-aefc-4c26cf537ea4"
      },
      "source": [
        "test_tanh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[46.964285714285715,\n",
              " 47.767857142857146,\n",
              " 48.16964285714286,\n",
              " 47.5,\n",
              " 47.00892857142857,\n",
              " 46.60714285714286]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 459
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aks-M62GUmeD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bff7b354-e060-4322-c285-17de40fa7aa4"
      },
      "source": [
        "sum(test_tanh[:-1])/len(test_tanh[:-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47.482142857142854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 460
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCUj-yerUpHZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ecbada68-f790-44dc-c6db-aca68a0cbbe3"
      },
      "source": [
        "sum(test_add)/len(test_add)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47.481142857142856"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 458
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c2IlzRaVd5V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f88959ec-d77e-4d37-8239-c55e9a2704e9"
      },
      "source": [
        "sum(test_add_notan)/len(test_add_notan)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47.29910714285714"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 515
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSZim36SZpvA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}